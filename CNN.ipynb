{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "Convolution Neural Networks은 이미지 분야를 다루기에 최적화된 인공 신경망 구조이다.  \n",
    "크게 Convolution Layer와 Pooling Layer로서 구성되어 있다.  \n",
    "- Convolution Layer: Convolution 연산을 통해서 이미지의 특징을 추출해내는 역활\n",
    "- Pooling Layer: 차원 축소하는 연산을 수행한다. **연산량을 감소** 시킬 수 있고, 이미지의 **가장 강한 특징만을 추출**하는 특징 선별효과가 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow API**  \n",
    "tf.nn.conv2d(\n",
    "input, \n",
    "filter,\n",
    "strides,\n",
    "padding,\n",
    "dilations=[1,1,1,1],\n",
    "name=None\n",
    ")\n",
    "\n",
    "- input: Input Data\n",
    "- filter: 컨볼루션 연산에 적용할 필터이며 [filter_height, filter_width, in_channels, out_channels]형태의 4-D Tensor만 가능\n",
    "- strides: 몇 Pixel씩 넘어갈지 지정\n",
    "- padding: \n",
    " - 'Same': zero padding을 통하여 input과 같은 크기의 이미지가 return\n",
    " - 'VALID': 컨볼루션 연산공식에 의해 계산된 가로, 세로, 차원이 리턴\n",
    "- dilation: Dilation Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.max_pool(\n",
    "value, \n",
    "ksize,\n",
    "strides,\n",
    "name=None\n",
    ")\n",
    "\n",
    "- value: Max Pooling을 적용시킬 Input Data\n",
    "- ksize: Max Pooling 연산에 적용할 필터이며 [batch_filter,height_filter, width_filter, channel_filter]형태의 4-D Tensor만 가능\n",
    "- strides: 몇 Pixel씩 넘어갈지 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.avg_pool;(\n",
    "value, \n",
    "ksize,\n",
    "strides,\n",
    "name=None\n",
    ")\n",
    "\n",
    "- value: Mean Pooling을 적용시킬 Input Data\n",
    "- ksize: Max Pooling 연산에 적용할 필터이며 [batch_filter,height_filter, width_filter, channel_filter]형태의 4-D Tensor만 가능\n",
    "- strides: 몇 Pixel씩 넘어갈지 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 실제 구현\n",
    "\n",
    "텐서플로 라이브러리를 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터를 다운받고 불러오는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c3d55fec490c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 모델을 정의  \n",
    "- Convolution Layer: 2개\n",
    "- Pooling Layer: 2개\n",
    "\n",
    "x_image를 [-1,28,28,1]을 통하여 Flatten한 1차원의 행렬로서 만든다.  \n",
    "따라서 W_conv1 이 [5,5,1,32] 즉 5x5 Filter를 Convolution으로 적용시키는데  \n",
    "Input의 차원은 1차원  \n",
    "Output의 차원은 32개로 나타낸다는 의미이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Definition\n",
    "def build_CNN_Classifier(x):\n",
    "    #MNIST 데이터를 3차원 형태로 reshape(흑백이므로 채널은 1)\n",
    "    x_image = tf.reshape(x,[-1,28,28,1])\n",
    "    \n",
    "    # 1_Convolution_Layer\n",
    "    # 5 x 5 Filter 32개 적용\n",
    "    # 28 x 28 => 28 x 28 x 32\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1],padding='SAME')+b_conv1)\n",
    "    \n",
    "    # 1_Pooling Layer\n",
    "    # Max_Pooling => Image size 1/2\n",
    "    # 28 x 28 x 32 => 14 x 14 x 32\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 2_Convolution_Layer\n",
    "    # 5 x 5 Filter 64개 적용\n",
    "    # 14 x 14 x 32 => 14 x 14 x 64\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2)\n",
    "    \n",
    "    # 2_Pooling Layer\n",
    "    # Max_Pooling => Image size 1/2\n",
    "    # 14 x 14 x 64 => 7 x 7 x 64\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 완전 연결층\n",
    "    # 7 x 7 크기를 가진 64개의 activation map을 1024개의 특징들로 변환\n",
    "    # 7 x 7 x 64(3136) => 1024\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64, 1024],stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1,shape=[1024]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "    \n",
    "    # 출력층\n",
    "    # 1024개의 특징들(feature)을 10개의 class로 변환\n",
    "    # 1024 -> 10\n",
    "    W_output = tf.Variable(tf.truncated_normal(shape=[1024,10],stddev=5e-2))\n",
    "    b_output = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "    logits = tf.matmul(h_fc1,W_output)+b_output\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input 과 Output 데이터를 받을 Place Holder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "y_pred, logits = build_CNN_Classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LosttFunction: Cross_Entropy_with_Softmax\n",
    "- Optimzer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-a1a7e11733c3>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(1e-04).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 출력하기 위한 연산들을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session을 열고 그래프 실행하여 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 0, 정확도: 0.120000\n",
      "반복(Epoch): 100, 정확도: 0.800000\n",
      "반복(Epoch): 200, 정확도: 0.920000\n",
      "반복(Epoch): 300, 정확도: 0.960000\n",
      "반복(Epoch): 400, 정확도: 0.940000\n",
      "반복(Epoch): 500, 정확도: 0.940000\n",
      "반복(Epoch): 600, 정확도: 0.900000\n",
      "반복(Epoch): 700, 정확도: 0.940000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f29afe84896f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'반복(Epoch): %d, 정확도: %f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#정확도 측정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #모든 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(3000):\n",
    "        #50개씩 MNIST 데이터를 불러온다.\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        \n",
    "        if i % 100 ==0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y:batch[1]})\n",
    "            print('반복(Epoch): %d, 정확도: %f'%(i, train_accuracy))\n",
    "            \n",
    "        sess.run([train_step], feed_dict={x:batch[0], y: batch[1]})\n",
    "        \n",
    "    #정확도 측정\n",
    "    print('Model 정확도: %f'%accuracy.eval(feed_dict={x:mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy.eval() 에서 .eval()은 run()과 같이 Session을 연 뒤 연산을 실행하는 과정이라고 생각하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR - 10\n",
    "CIFAR -10은 총 10개의 레이블로 구성된 이미지 분류를 위한 Dataset이다.  \n",
    "Image는 32 x 32의 크기의 이미지로 되어있고 또한  \n",
    "MNIST와 달리 Color Image인 것이 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Dropout은 Overfitting을 방지하기 위한 Regularization 기법의 일종이다.  \n",
    "**Tensorflow API**  \n",
    "tf.nn.dropout(\n",
    "x, \n",
    "keep_prob,\n",
    "name=None\n",
    ")\n",
    "\n",
    "- x: Dropout을 적용할 Input Data\n",
    "- keep_prob: 드롭하지 않고 유지할 노드의 비율을 나타내는 scalar 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN을 이용한 CIFAR-10 이미지 분류기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 라이브러리 import\n",
    "\n",
    "CIFAR-10 데이터셋을 다운받고, 불러오는 과정을 지원하는 helper 함수를 keras 모듈에서 load_data라는 모듈 함수로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets.cifar10 import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 배치 개수만큼 끊어서 읽어올 수 있는 next_batch 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "    \n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model을 정의  \n",
    "- Convolution Layer: 2개\n",
    "- Pooling Layer: 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Definition\n",
    "def build_CNN_Classifier(x):\n",
    "    #MNIST 데이터를 3차원 형태로 reshape(흑백이므로 채널은 1)\n",
    "    x_image = x\n",
    "    \n",
    "    # 1_Convolution_Layer\n",
    "    # RGB(Color) image를 64개의 feature으로 mapping 과정\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,3,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1],padding='SAME')+b_conv1)\n",
    "    \n",
    "    # 1_Pooling Layer\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 2_Convolution_Layer\n",
    "    # 64개의 feature을 다시 64개의 feature으로 mapping 하는 과정\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,64,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2)\n",
    "    \n",
    "    # 2_Pooling Layer\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 3_Convolution_Layer\n",
    "    # 64개의 feature을 다시 128개의 feature으로 mapping 하는 과정\n",
    "    W_conv3 = tf.Variable(tf.truncated_normal(shape=[3,3,64,128],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3,strides=[1,1,1,1],padding='SAME')+b_conv3)\n",
    "    \n",
    "    \n",
    "    # 4_Convolution_Layer\n",
    "    # 128개의 feature을 다시 128개의 feature으로 mapping 하는 과정\n",
    "    W_conv4 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4,strides=[1,1,1,1],padding='SAME')+b_conv4)\n",
    "    \n",
    "    \n",
    "    # 5_Convolution_Layer\n",
    "    # 128개의 feature을 다시 128개의 feature으로 mapping 하는 과정\n",
    "    W_conv5 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5,strides=[1,1,1,1],padding='SAME')+b_conv5)\n",
    "    \n",
    "    # 완전 연결층\n",
    "    # 2번의 downsampling 이후에, 32 x 32 이미지는 8 x 8 x 128의 Feature map으로 변환\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[8*8*128, 384],stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1,shape=[384]))\n",
    "    h_conv5_flat = tf.reshape(h_conv5,[-1,8*8*128])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat,W_fc1)+b_fc1)\n",
    "    \n",
    "    # Dropout - 모델의 복잡도를 컨트롤\n",
    "    # 특징들의 co-adaptation을 방지\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    # 완전 연결층2\n",
    "    # 384개의 feature를 10개의 class로 Mapping\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 10],stddev=5e-2))\n",
    "    b_fc2 = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "    logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x: Input Data\n",
    "- y: OutputData\n",
    "- keep_prob= 드롭아웃에서 드롭하지 않고 유지할 노드 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_data()함수를 이용하여 CIFAR-10 데이터를 다운로드하고 tf.one_hot API 를 이용해서 스칼라값 형태의 레이블 (0~9)을 One-hot-Encoding 형태로 변환\n",
    "\n",
    "- squeeze: Removes dimensions of size 1 from the shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "#Scalar 현태의 0 ~ 9 형태의 0 ~ 9 을 One - hot Encoding 형태로 변환\n",
    "y_train_one_hot = tf.squeeze(tf.one_hot(y_train,10),axis=1)\n",
    "y_test_one_hot = tf.squeeze(tf.one_hot(y_test,10),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 생성\n",
    "- Loss Function: Cross Entropy\n",
    "- Optimizer: RMSPropr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-ed025851b58d>:58: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "y_pred, logits = build_CNN_Classifier(x)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 계산하는 연산 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세션을 열어 그래프를 실행해서 학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 0, 정확도: 0.109375, 손실함수: 93.938210\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #모든 변수를 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10000):\n",
    "        batch = next_batch(128, x_train, y_train_one_hot.eval())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "            loss_print = loss.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "            \n",
    "            print('반복(Epoch): %d, 정확도: %f, 손실함수: %f'%(i, train_accuracy, loss_print))\n",
    "            \n",
    "            #20 % Dropout을 활용하여 학습을 진행\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y:batch[1], keep_prob:0.8})\n",
    "            \n",
    "    #학습이 끝나면 테스트 데이터에 대한 정확도를 출력\n",
    "    test_accuracy = 0.0\n",
    "    for i in range(10):\n",
    "        test_batch = next_batch(1000,x_test,y_test_one_hot.eval())\n",
    "        test_accuracy = test_accuracy + accuracy.eval(feed_dict={x: test_batch[0], y:test_batch[1], keep_prob: 1.0})\n",
    "            \n",
    "    test_accuracy = test_accuracy/10\n",
    "    print('테스트 데이터 정확도: %f'%(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
