{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "Convolution Neural Networks은 이미지 분야를 다루기에 최적화된 인공 신경망 구조이다.  \n",
    "크게 Convolution Layer와 Pooling Layer로서 구성되어 있다.  \n",
    "- Convolution Layer: Convolution 연산을 통해서 이미지의 특징을 추출해내는 역활\n",
    "- Pooling Layer: 차원 축소하는 연산을 수행한다. **연산량을 감소** 시킬 수 있고, 이미지의 **가장 강한 특징만을 추출**하는 특징 선별효과가 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow API**  \n",
    "tf.nn.conv2d(\n",
    "input, \n",
    "filter,\n",
    "strides,\n",
    "padding,\n",
    "dilations=[1,1,1,1],\n",
    "name=None\n",
    ")\n",
    "\n",
    "- input: Input Data\n",
    "- filter: 컨볼루션 연산에 적용할 필터이며 [filter_height, filter_width, in_channels, out_channels]형태의 4-D Tensor만 가능\n",
    "- strides: 몇 Pixel씩 넘어갈지 지정\n",
    "- padding: \n",
    " - 'Same': zero padding을 통하여 input과 같은 크기의 이미지가 return\n",
    " - 'VALID': 컨볼루션 연산공식에 의해 계산된 가로, 세로, 차원이 리턴\n",
    "- dilation: Dilation Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.max_pool(\n",
    "value, \n",
    "ksize,\n",
    "strides,\n",
    "name=None\n",
    ")\n",
    "\n",
    "- value: Max Pooling을 적용시킬 Input Data\n",
    "- ksize: Max Pooling 연산에 적용할 필터이며 [batch_filter,height_filter, width_filter, channel_filter]형태의 4-D Tensor만 가능\n",
    "- strides: 몇 Pixel씩 넘어갈지 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.avg_pool;(\n",
    "value, \n",
    "ksize,\n",
    "strides,\n",
    "name=None\n",
    ")\n",
    "\n",
    "- value: Mean Pooling을 적용시킬 Input Data\n",
    "- ksize: Max Pooling 연산에 적용할 필터이며 [batch_filter,height_filter, width_filter, channel_filter]형태의 4-D Tensor만 가능\n",
    "- strides: 몇 Pixel씩 넘어갈지 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 실제 구현\n",
    "\n",
    "텐서플로 라이브러리를 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터를 다운받고 불러오는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c3d55fec490c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 모델을 정의  \n",
    "- Convolution Layer: 2개\n",
    "- Pooling Layer: 2개 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])에서 -1으 data의 dimension을 모를 때 유용하게 사용할 수 있다.\n",
    "\n",
    "row 또는 Column중 하나만 값을 정해주고 나머지에 -1을 넣어준다면, 정해준 값에 맞춰서 reshape가 이루어 진다.\n",
    "\n",
    "즉 우리는 batch를 통하여 Trainning 을 하기 때문에 -1을 넣어주어서 batch size에 맞게 dynamic 한 input 행렬을 만들어야 하므로 [-1, 28, 28, 1]로서 정의한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Definition\n",
    "def build_CNN_Classifier(x):\n",
    "    #MNIST 데이터를 3차원 형태로 reshape(흑백이므로 채널은 1)\n",
    "    x_image = tf.reshape(x,[-1,28,28,1])\n",
    "    \n",
    "    # 1_Convolution_Layer\n",
    "    # 5 x 5 Filter 32개 적용\n",
    "    # 28 x 28 => 28 x 28 x 32\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1],padding='SAME')+b_conv1)\n",
    "    \n",
    "    # 1_Pooling Layer\n",
    "    # Max_Pooling => Image size 1/2\n",
    "    # 28 x 28 x 32 => 14 x 14 x 32\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 2_Convolution_Layer\n",
    "    # 5 x 5 Filter 64개 적용\n",
    "    # 14 x 14 x 32 => 14 x 14 x 64\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2)\n",
    "    \n",
    "    # 2_Pooling Layer\n",
    "    # Max_Pooling => Image size 1/2\n",
    "    # 14 x 14 x 64 => 7 x 7 x 64\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 완전 연결층\n",
    "    # 7 x 7 크기를 가진 64개의 activation map을 1024개의 특징들로 변환\n",
    "    # 7 x 7 x 64(3136) => 1024\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64, 1024],stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1,shape=[1024]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "    \n",
    "    # 출력층\n",
    "    # 1024개의 특징들(feature)을 10개의 class로 변환\n",
    "    # 1024 -> 10\n",
    "    W_output = tf.Variable(tf.truncated_normal(shape=[1024,10],stddev=5e-2))\n",
    "    b_output = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "    logits = tf.matmul(h_fc1,W_output)+b_output\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input 과 Output 데이터를 받을 Place Holder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "y_pred, logits = build_CNN_Classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LosttFunction: Cross_Entropy_with_Softmax\n",
    "- Optimzer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-a1a7e11733c3>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(1e-04).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 출력하기 위한 연산들을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session을 열고 그래프 실행하여 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 0, 정확도: 0.160000\n",
      "반복(Epoch): 100, 정확도: 0.740000\n",
      "반복(Epoch): 200, 정확도: 0.880000\n",
      "반복(Epoch): 300, 정확도: 0.920000\n",
      "반복(Epoch): 400, 정확도: 0.880000\n",
      "반복(Epoch): 500, 정확도: 0.980000\n",
      "반복(Epoch): 600, 정확도: 0.960000\n",
      "반복(Epoch): 700, 정확도: 0.920000\n",
      "반복(Epoch): 800, 정확도: 0.940000\n",
      "반복(Epoch): 900, 정확도: 0.980000\n",
      "반복(Epoch): 1000, 정확도: 0.960000\n",
      "반복(Epoch): 1100, 정확도: 0.980000\n",
      "반복(Epoch): 1200, 정확도: 0.980000\n",
      "반복(Epoch): 1300, 정확도: 0.980000\n",
      "반복(Epoch): 1400, 정확도: 1.000000\n",
      "반복(Epoch): 1500, 정확도: 0.960000\n",
      "반복(Epoch): 1600, 정확도: 0.920000\n",
      "반복(Epoch): 1700, 정확도: 0.980000\n",
      "반복(Epoch): 1800, 정확도: 1.000000\n",
      "반복(Epoch): 1900, 정확도: 0.980000\n",
      "반복(Epoch): 2000, 정확도: 0.980000\n",
      "반복(Epoch): 2100, 정확도: 1.000000\n",
      "반복(Epoch): 2200, 정확도: 1.000000\n",
      "반복(Epoch): 2300, 정확도: 0.980000\n",
      "반복(Epoch): 2400, 정확도: 0.980000\n",
      "반복(Epoch): 2500, 정확도: 0.980000\n",
      "반복(Epoch): 2600, 정확도: 0.980000\n",
      "반복(Epoch): 2700, 정확도: 1.000000\n",
      "반복(Epoch): 2800, 정확도: 0.980000\n",
      "반복(Epoch): 2900, 정확도: 0.980000\n",
      "Model 정확도: 0.983400\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #모든 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(3000):\n",
    "        #50개씩 MNIST 데이터를 불러온다.\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        \n",
    "        if i % 100 ==0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y:batch[1]})\n",
    "            print('반복(Epoch): %d, 정확도: %f'%(i, train_accuracy))\n",
    "            \n",
    "        sess.run([train_step], feed_dict={x:batch[0], y: batch[1]})\n",
    "        \n",
    "    #정확도 측정\n",
    "    print('Model 정확도: %f'%accuracy.eval(feed_dict={x:mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy.eval() 에서 .eval()은 run()과 같이 Session을 연 뒤 연산을 실행하는 과정이라고 생각하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR - 10\n",
    "CIFAR -10은 총 10개의 레이블로 구성된 이미지 분류를 위한 Dataset이다.  \n",
    "Image는 32 x 32의 크기의 이미지로 되어있고 또한  \n",
    "MNIST와 달리 Color Image인 것이 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Dropout은 Overfitting을 방지하기 위한 Regularization 기법의 일종이다.  \n",
    "**Tensorflow API**  \n",
    "tf.nn.dropout(\n",
    "x, \n",
    "keep_prob,\n",
    "name=None\n",
    ")\n",
    "\n",
    "- x: Dropout을 적용할 Input Data\n",
    "- keep_prob: 드롭하지 않고 유지할 노드의 비율을 나타내는 scalar 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN을 이용한 CIFAR-10 이미지 분류기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 라이브러리 import\n",
    "\n",
    "CIFAR-10 데이터셋을 다운받고, 불러오는 과정을 지원하는 helper 함수를 keras 모듈에서 load_data라는 모듈 함수로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets.cifar10 import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 배치 개수만큼 끊어서 읽어올 수 있는 next_batch 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "    \n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model을 정의  \n",
    "- Convolution Layer: 5개\n",
    "- Pooling Layer: 2개\n",
    "- DropOut Layer: 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Definition\n",
    "def build_CNN_Classifier(x):\n",
    "    x_image = x\n",
    "    \n",
    "    # 1_Convolution_Layer\n",
    "    # RGB(Color) image를 64개의 feature으로 mapping 과정\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,3,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1],padding='SAME')+b_conv1)\n",
    "    \n",
    "    # 1_Pooling Layer\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 2_Convolution_Layer\n",
    "    # 64개의 feature을 다시 64개의 feature으로 mapping 하는 과정\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,64,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2)\n",
    "    \n",
    "    # 2_Pooling Layer\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 3_Convolution_Layer\n",
    "    # 64개의 feature을 다시 128개의 feature으로 mapping 하는 과정\n",
    "    W_conv3 = tf.Variable(tf.truncated_normal(shape=[3,3,64,128],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3,strides=[1,1,1,1],padding='SAME')+b_conv3)\n",
    "    \n",
    "    \n",
    "    # 4_Convolution_Layer\n",
    "    # 128개의 feature을 다시 128개의 feature으로 mapping 하는 과정\n",
    "    W_conv4 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4,strides=[1,1,1,1],padding='SAME')+b_conv4)\n",
    "    \n",
    "    \n",
    "    # 5_Convolution_Layer\n",
    "    # 128개의 feature을 다시 128개의 feature으로 mapping 하는 과정\n",
    "    W_conv5 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5,strides=[1,1,1,1],padding='SAME')+b_conv5)\n",
    "    \n",
    "    # 완전 연결층\n",
    "    # 2번의 downsampling 이후에, 32 x 32 이미지는 8 x 8 x 128의 Feature map으로 변환\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[8*8*128, 384],stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1,shape=[384]))\n",
    "    h_conv5_flat = tf.reshape(h_conv5,[-1,8*8*128])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat,W_fc1)+b_fc1)\n",
    "    \n",
    "    # Dropout - 모델의 복잡도를 컨트롤\n",
    "    # 특징들의 co-adaptation을 방지\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    # 완전 연결층2\n",
    "    # 384개의 feature를 10개의 class로 Mapping\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 10],stddev=5e-2))\n",
    "    b_fc2 = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "    logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x: Input Data\n",
    "- y: OutputData\n",
    "- keep_prob= 드롭아웃에서 드롭하지 않고 유지할 노드 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_data()함수를 이용하여 CIFAR-10 데이터를 다운로드하고 tf.one_hot API 를 이용해서 스칼라값 형태의 레이블 (0~9)을 One-hot-Encoding 형태로 변환\n",
    "\n",
    "- squeeze: Removes dimensions of size 1 from the shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "#Scalar 현태의 0 ~ 9 형태의 0 ~ 9 을 One - hot Encoding 형태로 변환\n",
    "y_train_one_hot = tf.squeeze(tf.one_hot(y_train,10),axis=1)\n",
    "y_test_one_hot = tf.squeeze(tf.one_hot(y_test,10),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 생성\n",
    "- Loss Function: Cross Entropy\n",
    "- Optimizer: RMSPropr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-ed025851b58d>:58: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "y_pred, logits = build_CNN_Classifier(x)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 계산하는 연산 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세션을 열어 그래프를 실행해서 학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 0, 정확도: 0.109375, 손실함수: 101.231110\n",
      "반복(Epoch): 100, 정확도: 0.148438, 손실함수: 2.251683\n",
      "반복(Epoch): 200, 정확도: 0.296875, 손실함수: 2.232113\n",
      "반복(Epoch): 300, 정확도: 0.312500, 손실함수: 1.844951\n",
      "반복(Epoch): 400, 정확도: 0.492188, 손실함수: 1.533695\n",
      "반복(Epoch): 500, 정확도: 0.453125, 손실함수: 1.487141\n",
      "반복(Epoch): 600, 정확도: 0.531250, 손실함수: 1.406302\n",
      "반복(Epoch): 700, 정확도: 0.531250, 손실함수: 1.232612\n",
      "반복(Epoch): 800, 정확도: 0.515625, 손실함수: 1.335735\n",
      "반복(Epoch): 900, 정확도: 0.523438, 손실함수: 1.293202\n",
      "반복(Epoch): 1000, 정확도: 0.632812, 손실함수: 1.094189\n",
      "반복(Epoch): 1100, 정확도: 0.609375, 손실함수: 1.102321\n",
      "반복(Epoch): 1200, 정확도: 0.570312, 손실함수: 1.166264\n",
      "반복(Epoch): 1300, 정확도: 0.578125, 손실함수: 1.209377\n",
      "반복(Epoch): 1400, 정확도: 0.609375, 손실함수: 1.090788\n",
      "반복(Epoch): 1500, 정확도: 0.593750, 손실함수: 1.143198\n",
      "반복(Epoch): 1600, 정확도: 0.609375, 손실함수: 1.072623\n",
      "반복(Epoch): 1700, 정확도: 0.625000, 손실함수: 1.026142\n",
      "반복(Epoch): 1800, 정확도: 0.656250, 손실함수: 1.073173\n",
      "반복(Epoch): 1900, 정확도: 0.625000, 손실함수: 1.119134\n",
      "반복(Epoch): 2000, 정확도: 0.710938, 손실함수: 0.781481\n",
      "반복(Epoch): 2100, 정확도: 0.625000, 손실함수: 1.011171\n",
      "반복(Epoch): 2200, 정확도: 0.609375, 손실함수: 1.136861\n",
      "반복(Epoch): 2300, 정확도: 0.750000, 손실함수: 0.827670\n",
      "반복(Epoch): 2400, 정확도: 0.664062, 손실함수: 0.932119\n",
      "반복(Epoch): 2500, 정확도: 0.726562, 손실함수: 0.940305\n",
      "반복(Epoch): 2600, 정확도: 0.664062, 손실함수: 1.013748\n",
      "반복(Epoch): 2700, 정확도: 0.687500, 손실함수: 0.944589\n",
      "반복(Epoch): 2800, 정확도: 0.679688, 손실함수: 0.835967\n",
      "반복(Epoch): 2900, 정확도: 0.671875, 손실함수: 0.892465\n",
      "반복(Epoch): 3000, 정확도: 0.726562, 손실함수: 0.901456\n",
      "반복(Epoch): 3100, 정확도: 0.554688, 손실함수: 1.279375\n",
      "반복(Epoch): 3200, 정확도: 0.656250, 손실함수: 1.095811\n",
      "반복(Epoch): 3300, 정확도: 0.515625, 손실함수: 1.344259\n",
      "반복(Epoch): 3400, 정확도: 0.664062, 손실함수: 0.956214\n",
      "반복(Epoch): 3500, 정확도: 0.664062, 손실함수: 0.973765\n",
      "반복(Epoch): 3600, 정확도: 0.710938, 손실함수: 0.983459\n",
      "반복(Epoch): 3700, 정확도: 0.695312, 손실함수: 0.975849\n",
      "반복(Epoch): 3800, 정확도: 0.617188, 손실함수: 0.969750\n",
      "반복(Epoch): 3900, 정확도: 0.695312, 손실함수: 0.996568\n",
      "반복(Epoch): 4000, 정확도: 0.671875, 손실함수: 0.856737\n",
      "반복(Epoch): 4100, 정확도: 0.656250, 손실함수: 1.030292\n",
      "반복(Epoch): 4200, 정확도: 0.632812, 손실함수: 1.061514\n",
      "반복(Epoch): 4300, 정확도: 0.656250, 손실함수: 1.136145\n",
      "반복(Epoch): 4400, 정확도: 0.718750, 손실함수: 1.173640\n",
      "반복(Epoch): 4500, 정확도: 0.750000, 손실함수: 0.721899\n",
      "반복(Epoch): 4600, 정확도: 0.695312, 손실함수: 0.940879\n",
      "반복(Epoch): 4700, 정확도: 0.679688, 손실함수: 0.948310\n",
      "반복(Epoch): 4800, 정확도: 0.734375, 손실함수: 0.875695\n",
      "반복(Epoch): 4900, 정확도: 0.671875, 손실함수: 1.010897\n",
      "반복(Epoch): 5000, 정확도: 0.687500, 손실함수: 1.032740\n",
      "반복(Epoch): 5100, 정확도: 0.687500, 손실함수: 0.961322\n",
      "반복(Epoch): 5200, 정확도: 0.632812, 손실함수: 0.954187\n",
      "반복(Epoch): 5300, 정확도: 0.703125, 손실함수: 0.880058\n",
      "반복(Epoch): 5400, 정확도: 0.585938, 손실함수: 1.064903\n",
      "반복(Epoch): 5500, 정확도: 0.593750, 손실함수: 0.973062\n",
      "반복(Epoch): 5600, 정확도: 0.726562, 손실함수: 0.779956\n",
      "반복(Epoch): 5700, 정확도: 0.734375, 손실함수: 0.843649\n",
      "반복(Epoch): 5800, 정확도: 0.734375, 손실함수: 0.778181\n",
      "반복(Epoch): 5900, 정확도: 0.671875, 손실함수: 0.982531\n",
      "반복(Epoch): 6000, 정확도: 0.640625, 손실함수: 0.993726\n",
      "반복(Epoch): 6100, 정확도: 0.742188, 손실함수: 0.756626\n",
      "반복(Epoch): 6200, 정확도: 0.671875, 손실함수: 0.906797\n",
      "반복(Epoch): 6300, 정확도: 0.734375, 손실함수: 0.817923\n",
      "반복(Epoch): 6400, 정확도: 0.765625, 손실함수: 0.682222\n",
      "반복(Epoch): 6500, 정확도: 0.695312, 손실함수: 0.813831\n",
      "반복(Epoch): 6600, 정확도: 0.570312, 손실함수: 1.186363\n",
      "반복(Epoch): 6700, 정확도: 0.632812, 손실함수: 1.250628\n",
      "반복(Epoch): 6800, 정확도: 0.554688, 손실함수: 1.097521\n",
      "반복(Epoch): 6900, 정확도: 0.703125, 손실함수: 0.797140\n",
      "반복(Epoch): 7000, 정확도: 0.734375, 손실함수: 0.841882\n",
      "반복(Epoch): 7100, 정확도: 0.687500, 손실함수: 1.073199\n",
      "반복(Epoch): 7200, 정확도: 0.664062, 손실함수: 0.841093\n",
      "반복(Epoch): 7300, 정확도: 0.679688, 손실함수: 0.994022\n",
      "반복(Epoch): 7400, 정확도: 0.679688, 손실함수: 0.833868\n",
      "반복(Epoch): 7500, 정확도: 0.703125, 손실함수: 0.959638\n",
      "반복(Epoch): 7600, 정확도: 0.710938, 손실함수: 0.865158\n",
      "반복(Epoch): 7700, 정확도: 0.687500, 손실함수: 0.924053\n",
      "반복(Epoch): 7800, 정확도: 0.695312, 손실함수: 0.786567\n",
      "반복(Epoch): 7900, 정확도: 0.703125, 손실함수: 0.780130\n",
      "반복(Epoch): 8000, 정확도: 0.710938, 손실함수: 0.867213\n",
      "반복(Epoch): 8100, 정확도: 0.593750, 손실함수: 1.147878\n",
      "반복(Epoch): 8200, 정확도: 0.648438, 손실함수: 0.967397\n",
      "반복(Epoch): 8300, 정확도: 0.726562, 손실함수: 0.972790\n",
      "반복(Epoch): 8400, 정확도: 0.578125, 손실함수: 1.194548\n",
      "반복(Epoch): 8500, 정확도: 0.781250, 손실함수: 0.730035\n",
      "반복(Epoch): 8600, 정확도: 0.710938, 손실함수: 0.835205\n",
      "반복(Epoch): 8700, 정확도: 0.609375, 손실함수: 1.097136\n",
      "반복(Epoch): 8800, 정확도: 0.718750, 손실함수: 0.805593\n",
      "반복(Epoch): 8900, 정확도: 0.656250, 손실함수: 0.841182\n",
      "반복(Epoch): 9000, 정확도: 0.671875, 손실함수: 0.936324\n",
      "반복(Epoch): 9100, 정확도: 0.718750, 손실함수: 0.919038\n",
      "반복(Epoch): 9200, 정확도: 0.718750, 손실함수: 1.474803\n",
      "반복(Epoch): 9300, 정확도: 0.742188, 손실함수: 0.762006\n",
      "반복(Epoch): 9400, 정확도: 0.664062, 손실함수: 1.021962\n",
      "반복(Epoch): 9500, 정확도: 0.492188, 손실함수: 1.413232\n",
      "반복(Epoch): 9600, 정확도: 0.656250, 손실함수: 1.104025\n",
      "반복(Epoch): 9700, 정확도: 0.695312, 손실함수: 0.826372\n",
      "반복(Epoch): 9800, 정확도: 0.710938, 손실함수: 0.783436\n",
      "반복(Epoch): 9900, 정확도: 0.609375, 손실함수: 1.050041\n",
      "테스트 데이터 정확도: 0.642000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #모든 변수를 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10000):\n",
    "        batch = next_batch(128, x_train, y_train_one_hot.eval())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "            loss_print = loss.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "            \n",
    "            print('반복(Epoch): %d, 정확도: %f, 손실함수: %f'%(i, train_accuracy, loss_print))\n",
    "            \n",
    "            #20 % Dropout을 활용하여 학습을 진행\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y:batch[1], keep_prob:0.8})\n",
    "            \n",
    "    #학습이 끝나면 테스트 데이터에 대한 정확도를 출력\n",
    "    test_accuracy = 0.0\n",
    "    for i in range(10):\n",
    "        test_batch = next_batch(1000,x_test,y_test_one_hot.eval())\n",
    "        test_accuracy = test_accuracy + accuracy.eval(feed_dict={x: test_batch[0], y:test_batch[1], keep_prob: 1.0})\n",
    "            \n",
    "    test_accuracy = test_accuracy/10\n",
    "    print('테스트 데이터 정확도: %f'%(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train.Saver API\n",
    "tf.train.Saver API 란 모델과 파라미터를 저장하고 불러오는 방법이다.  \n",
    "딥러닝 기법을 이용해서 복잡한 문제를 해결할 때는 수많은 횟수를 반복해서 파라미터를 업데이트 해야 하나 매번 바닥부터 파라미터를 새로 업데이트하는 것은 비효율적이므로 학습한 모델의 파라미터를 저장하고 불러오는 방법을 사용한다.  \n",
    "1. tf.train.Saver() 클래스를 선언\n",
    "2. 선언한 tf.train.Saver()클래스의 save(sess, save_path, global_step=None)함수를 호출해서 모델과 파라미터를 저장한다.  \n",
    "1) save_path: 모델과 파라미터를 저장할 폴더경로 + 저장할 이름  \n",
    "2) global_step: 반복회수  \n",
    "3. restore(sess, save_path): 저장된 모델과 파라미터를 불러오는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에 선언된 CNN 모델을 이용한 MNIST 숫자 분류기 코드에 tf.train.Saver API 를 이용해서 학습한 모델의 파라미터를 저장하고 불러오는 방법 사용  \n",
    "Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Definition\n",
    "def build_CNN_Classifier(x):\n",
    "    #MNIST 데이터를 3차원 형태로 reshape(흑백이므로 채널은 1)\n",
    "    x_image = tf.reshape(x,[-1,28,28,1])\n",
    "    \n",
    "    # 1_Convolution_Layer\n",
    "    # RGB(Color) image를 64개의 feature으로 mapping 과정\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1],padding='SAME')+b_conv1)\n",
    "    \n",
    "    # 1_Pooling Layer\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # 2_Convolution_Layer\n",
    "    # 64개의 feature을 다시 64개의 feature으로 mapping 하는 과정\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64],stddev=5e-2))\n",
    "    #truncated: 정규 분포로서 출력\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2)\n",
    "    \n",
    "    # 2_Pooling Layer\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "    # 완전 연결층\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64, 1024],stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1,shape=[1024]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "    \n",
    "    #출력층\n",
    "    W_output = tf.Variable(tf.truncated_normal(shape=[1024,10],stddev=5e-2))\n",
    "    b_output = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "    logits = tf.matmul(h_fc1,W_output)+b_output\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인풋, 아웃풋 데이터를 받기위한 플레이스 홀더를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, logits = build_CNN_Classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LosttFunction: Cross_Entropy_with_Softmax\n",
    "- Optimzer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(1e-04).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 출력하기 위한 연산들을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.train.Saver를 이용해서 모델과 파라미터를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SAVE_DIR = 'model'\n",
    "saver = tf.train.Saver()\n",
    "chekpoint_path = os.path.join(SAVE_DIR, 'model')\n",
    "ckpt = tf.train.get_checkpoint_state(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session을 열고 그래프 실행하여 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 0, 정확도: 0.100000\n",
      "반복(Epoch): 100, 정확도: 0.860000\n",
      "반복(Epoch): 200, 정확도: 0.880000\n",
      "반복(Epoch): 300, 정확도: 0.940000\n",
      "반복(Epoch): 400, 정확도: 0.940000\n",
      "WARNING:tensorflow:From C:\\Tensor\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "반복(Epoch): 500, 정확도: 0.940000\n",
      "반복(Epoch): 600, 정확도: 0.920000\n",
      "반복(Epoch): 700, 정확도: 0.940000\n",
      "반복(Epoch): 800, 정확도: 0.940000\n",
      "반복(Epoch): 900, 정확도: 0.880000\n",
      "반복(Epoch): 1000, 정확도: 0.980000\n",
      "반복(Epoch): 1100, 정확도: 0.940000\n",
      "반복(Epoch): 1200, 정확도: 0.960000\n",
      "반복(Epoch): 1300, 정확도: 0.960000\n",
      "반복(Epoch): 1400, 정확도: 0.980000\n",
      "반복(Epoch): 1500, 정확도: 1.000000\n",
      "반복(Epoch): 1600, 정확도: 1.000000\n",
      "반복(Epoch): 1700, 정확도: 0.940000\n",
      "반복(Epoch): 1800, 정확도: 1.000000\n",
      "반복(Epoch): 1900, 정확도: 1.000000\n",
      "반복(Epoch): 2000, 정확도: 0.980000\n",
      "반복(Epoch): 2100, 정확도: 0.960000\n",
      "반복(Epoch): 2200, 정확도: 1.000000\n",
      "반복(Epoch): 2300, 정확도: 1.000000\n",
      "반복(Epoch): 2400, 정확도: 0.980000\n",
      "반복(Epoch): 2500, 정확도: 1.000000\n",
      "반복(Epoch): 2600, 정확도: 0.960000\n",
      "반복(Epoch): 2700, 정확도: 0.960000\n",
      "반복(Epoch): 2800, 정확도: 1.000000\n",
      "반복(Epoch): 2900, 정확도: 0.980000\n",
      "Model 정확도: 0.984500\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #모든 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #만약 저장된 모델과 파라미터가 있으면 이를 불러오고(Restore)\n",
    "    #Restored 모델을 이용해서 테스트 데이터에 대한 정확도를 출력하고 프로그램을 종료\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        print('테스트 데이터 정확도(Restored): %f'%accuracy.eval(feed_dict={x: mnist.test.images, y:mnist.test.labels}))\n",
    "        sess.close()\n",
    "        exit()\n",
    "    \n",
    "    for i in range(3000):\n",
    "        #50개씩 MNIST 데이터를 불러온다.\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        \n",
    "        if i % 100 ==0:\n",
    "            saver.save(sess,chekpoint_path,global_step=i)\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y:batch[1]})\n",
    "            print('반복(Epoch): %d, 정확도: %f'%(i, train_accuracy))\n",
    "            \n",
    "        sess.run([train_step], feed_dict={x:batch[0], y: batch[1]})\n",
    "        \n",
    "    #정확도 측정\n",
    "    print('Model 정확도: %f'%accuracy.eval(feed_dict={x:mnist.test.images, y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
